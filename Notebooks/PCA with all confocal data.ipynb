{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de49c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#import stuff and define functions\n",
    "from typing import Dict, List, Optional, Union\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from CustomFunctions import shapePCAtools\n",
    "import math\n",
    "from vtk.util import numpy_support\n",
    "import vtk\n",
    "from aicsshparam import shtools\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29c8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# gather data from all experiments ###############\n",
    "folders = ['Galvanotaxis_Confocal_40x_30C_10s',\n",
    "           'Galvanotaxis_Confocal_40x_30C_6s',\n",
    "          'CK666']\n",
    "lst = []\n",
    "for f in folders:\n",
    "    tempfl = f'D:/Aaron/Data/{f}/Data_and_Figs/'\n",
    "    df = pd.read_csv(tempfl + 'Shape_Metrics_outliersremoved.csv', index_col='cell')\n",
    "    excludes = pd.read_csv(tempfl + 'ListToExclude.csv', index_col=0)\n",
    "    exlist = [i.replace('_segmented.tiff', '') for i in excludes.iloc[:,0].to_list()]\n",
    "    df = df.loc[[x for x in df.index if x not in exlist]]\n",
    "    lst.append(df)\n",
    "df = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e326a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Perform PCA and divide cells into shape space bins ################\n",
    "\n",
    "\n",
    "savedir = 'D:/Aaron/Data/Combined_Confocal_PCA/'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "#specify number of PCs and number of bins\n",
    "npcs = 10\n",
    "nbins = 5\n",
    "bins = list(range(1,nbins+1))\n",
    "lmax = 10\n",
    "\n",
    "\n",
    "#get coeffs only\n",
    "coeff_df = df[[x for x in df.columns.to_list() if 'shcoeffs' in x]]\n",
    "\n",
    "\n",
    "# Fit and transform the data\n",
    "pca = PCA(n_components=npcs)\n",
    "pca = pca.fit(coeff_df)\n",
    "matrix_of_features_transform = pca.transform(coeff_df)\n",
    "\n",
    "\n",
    "# Dataframe of transformed variable\n",
    "pc_names = [f\"Cell_PC{c}\" for c in range(1, 1 + npcs)]\n",
    "df_trans = pd.DataFrame(data=matrix_of_features_transform, columns=pc_names, index = coeff_df.index)\n",
    "\n",
    "\n",
    "# Adjust the sign of PCs so that larger cells are represent by positive values\n",
    "#need actual volume data to do this so needs to be combined with shape metrics\n",
    "df_trans['Cell_Volume'] = df.Cell_Volume\n",
    "for pcid, pc_name in enumerate(pc_names):\n",
    "    pearson = np.corrcoef(df_trans.Cell_Volume.values, df_trans[pc_name].values)\n",
    "    if pearson[0, 1] < 0:\n",
    "        df_trans[pc_name] *= -1\n",
    "        pca.components_[pcid] *= -1\n",
    "\n",
    "df_trans = df_trans.drop(columns = 'Cell_Volume')\n",
    "\n",
    "\n",
    "\n",
    "################ RECONSTRUCT CELLS AT CERTAIN POINTS IN THE \"SHAPE SPACE\" ##################\n",
    "\n",
    "df_dig = pd.DataFrame(index = df_trans.index)\n",
    "for count, col in enumerate(df_trans.columns.to_list()):\n",
    "    df_digit, bin_indexes, (bin_centers, pc_std) = shapePCAtools.digitize_shape_mode(\n",
    "        df = df_trans,\n",
    "        feature = col,\n",
    "        nbins = nbins,\n",
    "        filter_based_on = df_trans.columns.to_list(),\n",
    "        filter_extremes_pct = float(1),\n",
    "        save = None,\n",
    "        return_freqs_per_structs = False\n",
    "    )\n",
    "    #put bin_indexes into a larger list that I can later iterate through\n",
    "    df_dig = df_dig.merge(df_digit[[col,'bin']], left_index = True, right_index = True)\n",
    "    df_dig = df_dig.rename(columns={'bin':f'PC{count+1}_bins'})\n",
    "\n",
    "    \n",
    "mid = math.ceil(nbins/2)\n",
    "recon_PCs = np.zeros((npcs, nbins, npcs))\n",
    "for pi, p in enumerate(pc_names):\n",
    "    for c in range(nbins):\n",
    "        for ni, n in enumerate(pc_names):\n",
    "            if n == p:\n",
    "                recon_PCs[pi,c,ni] = df_dig[df_dig[f'PC{ni+1}_bins']==c+1].loc[:,n].mean()\n",
    "            else:\n",
    "                recon_PCs[pi,c,ni] = df_dig[df_dig[f'PC{ni+1}_bins']==mid].loc[:,n].mean()\n",
    "\n",
    "#get inverse pca transform of those values\n",
    "recon_schoeffs = np.zeros((npcs, nbins, len(coeff_df.columns)))\n",
    "for o in range(recon_schoeffs.shape[0]):\n",
    "    for t in range(recon_schoeffs.shape[1]):\n",
    "            recon_schoeffs[o,t,:] = pca.inverse_transform(recon_PCs[o,t,:])\n",
    "            \n",
    "    \n",
    "#combine metrics and digitized pcs\n",
    "df_dig = df.merge(df_dig, left_index = True, right_index = True)\n",
    "#save\n",
    "df_dig.to_csv(savedir+\"Shape_Metrics_with_Digitized_PCs.csv\")\n",
    "\n",
    "\n",
    "########### GET RECONSTRUCTIONS OF AVERAGE CELLS FROM SHAPE SPACE BINS ##########################\n",
    "\n",
    "meshes = {}\n",
    "aliases = ['Cell']\n",
    "\n",
    "for pi, p in enumerate(pc_names):\n",
    "    meshes[p] = {}\n",
    "    for c in range(nbins):\n",
    "        meshes[p][bins[c]] = {}\n",
    "        row = pd.Series(recon_schoeffs[pi,c,:], index = coeff_df.columns.to_list())\n",
    "        for i, a in enumerate(aliases):\n",
    "            mesh, _ = shtools.get_reconstruction_from_coeffs(recon_schoeffs[pi,c,:].reshape(2,lmax+1,lmax+1))\n",
    "            meshes[p][bins[c]][a] = mesh\n",
    "\n",
    "                \n",
    "                \n",
    "################## save PC meshes ##################\n",
    "pcmeshdir = savedir + 'PC_Meshes/'\n",
    "if not os.path.exists(pcmeshdir):\n",
    "    os.makedirs(pcmeshdir)\n",
    "for p in list(meshes):\n",
    "    for n, b in enumerate(list(meshes[p])):\n",
    "        for a in list(meshes[p][b]):\n",
    "            writer = vtk.vtkXMLPolyDataWriter()\n",
    "            writer.SetFileName(pcmeshdir+p+'_'+str(b)+'_'+a+'.vtp')\n",
    "            writer.SetInputData(meshes[p][b][a])\n",
    "            writer.Write()\n",
    "\n",
    "####### also save the pca object for later use ###########\n",
    "pk.dump(pca, open(data_fl+\"pca.pkl\",\"wb\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:abhishape] *",
   "language": "python",
   "name": "conda-env-abhishape-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
