{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "silent-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "import seaborn as sns\n",
    "import math\n",
    "from math import sqrt, factorial\n",
    "import re\n",
    "from itertools import groupby\n",
    "import scipy\n",
    "import random\n",
    "from decimal import Decimal\n",
    "from operator import itemgetter\n",
    "import multiprocessing\n",
    "from CustomFunctions import PCvisualization\n",
    "\n",
    "def cllct_rslts(result):\n",
    "    \"\"\"Uses apply_async's callback to setup up a separate Queue for each process.\n",
    "    This will allow us to collect the results from different threads.\"\"\"\n",
    "    results.extend(result)\n",
    "def collect_results(result):\n",
    "    \"\"\"Uses apply_async's callback to setup up a separate Queue for each process.\n",
    "    This will allow us to collect the results from different threads.\"\"\"\n",
    "    results.append(result)\n",
    "\n",
    "\n",
    "#some functions that help find angles between planes\n",
    "\n",
    "#https://keisan.casio.com/exec/system/1223596129\n",
    "def plane_eq(points):\n",
    "    p0 = points[0,:]\n",
    "    p1 = points[1,:]\n",
    "    p2 = points[2,:]\n",
    "    v1 = [p1[0]-p0[0], p1[1]-p0[1], p1[2]-p0[2]]\n",
    "    v2 = [p2[0]-p0[0], p2[1]-p0[1], p2[2]-p0[2]]\n",
    "    abc = np.cross(v1, v2)\n",
    "    d = np.array([abc[0]*p0[0], abc[1]*p0[1], abc[2]*p0[2]])\n",
    "    return abc, d\n",
    "# Function to find Angle\n",
    "def distance(a1, b1, c1, a2, b2, c2):\n",
    "     \n",
    "    d = ( a1 * a2 + b1 * b2 + c1 * c2 )\n",
    "    e1 = math.sqrt( a1 * a1 + b1 * b1 + c1 * c1)\n",
    "    e2 = math.sqrt( a2 * a2 + b2 * b2 + c2 * c2)\n",
    "    d = d / (e1 * e2)\n",
    "    A = math.degrees(math.acos(d))\n",
    "    return A\n",
    "\n",
    "def angle(a1, b1, a2, b2):\n",
    "     \n",
    "    d = ( a1 * a2 + b1 * b2)\n",
    "    e1 = math.sqrt( a1 * a1 + b1 * b1)\n",
    "    e2 = math.sqrt( a2 * a2 + b2 * b2)\n",
    "    d = d / (e1 * e2)\n",
    "    A = math.degrees(math.acos(d))\n",
    "    return A\n",
    "def closest(lst, K):  \n",
    "    return lst[min(range(len(lst)), key = lambda i: abs(lst[i]-K))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "italic-documentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get directories and open separated datasets\n",
    "\n",
    "time_interval = 5 #sec/frame\n",
    "\n",
    "datadir = 'E:/Aaron/random_lls/'\n",
    "savedir = datadir + 'random/'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "TotalFrame = pd.read_csv(datadir + 'Shape_Metrics_transitionPCbins.csv', index_col=0)\n",
    "\n",
    "centers = pd.read_csv(datadir+'PC_bin_centers.csv', index_col=0)\n",
    "\n",
    "nbins = np.max(TotalFrame[[x for x in TotalFrame.columns.to_list() if 'bin' in x]].to_numpy())\n",
    "\n",
    "#restrict dataframe to only random experiments\n",
    "TotalFrame = TotalFrame[TotalFrame.Treatment=='Random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished interpolating trajectories for PC1-PC2\n",
      "39602.97773744365\n",
      "Finished finding transition rates for PC1-PC2\n",
      "Finished interpolating trajectories for PC1-PC3\n",
      "39752.699331068354\n",
      "Finished finding transition rates for PC1-PC3\n",
      "Finished interpolating trajectories for PC1-PC4\n",
      "39554.87175138004\n",
      "Finished finding transition rates for PC1-PC4\n",
      "Finished interpolating trajectories for PC1-PC5\n",
      "39518.337088436034\n",
      "Finished finding transition rates for PC1-PC5\n",
      "Finished interpolating trajectories for PC1-PC6\n",
      "39737.82467529362\n",
      "Finished finding transition rates for PC1-PC6\n",
      "Finished interpolating trajectories for PC1-PC7\n",
      "39682.86909193771\n",
      "Finished finding transition rates for PC1-PC7\n",
      "Finished interpolating trajectories for PC1-PC8\n",
      "40069.79411251415\n",
      "Finished finding transition rates for PC1-PC8\n",
      "Finished interpolating trajectories for PC1-PC9\n",
      "39968.53723502492\n",
      "Finished finding transition rates for PC1-PC9\n",
      "Finished interpolating trajectories for PC1-PC10\n",
      "39876.14290602604\n",
      "Finished finding transition rates for PC1-PC10\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for PC2-PC3\n",
      "39799.283251428176\n",
      "Finished finding transition rates for PC2-PC3\n",
      "Finished interpolating trajectories for PC2-PC4\n",
      "39729.9912458377\n",
      "Finished finding transition rates for PC2-PC4\n",
      "Finished interpolating trajectories for PC2-PC5\n",
      "39661.2183073801\n",
      "Finished finding transition rates for PC2-PC5\n",
      "Finished interpolating trajectories for PC2-PC6\n",
      "39810.373078676916\n",
      "Finished finding transition rates for PC2-PC6\n",
      "Finished interpolating trajectories for PC2-PC7\n",
      "39812.847403164655\n",
      "Finished finding transition rates for PC2-PC7\n",
      "Finished interpolating trajectories for PC2-PC8\n",
      "40112.59002023405\n",
      "Finished finding transition rates for PC2-PC8\n",
      "Finished interpolating trajectories for PC2-PC9\n",
      "39944.738181050954\n",
      "Finished finding transition rates for PC2-PC9\n",
      "Finished interpolating trajectories for PC2-PC10\n",
      "39992.446225193264\n",
      "Finished finding transition rates for PC2-PC10\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for PC3-PC4\n",
      "39900.84939253011\n",
      "Finished finding transition rates for PC3-PC4\n",
      "Finished interpolating trajectories for PC3-PC5\n",
      "39807.212051580784\n",
      "Finished finding transition rates for PC3-PC5\n",
      "Finished interpolating trajectories for PC3-PC6\n",
      "39813.25259452985\n",
      "Finished finding transition rates for PC3-PC6\n",
      "Finished interpolating trajectories for PC3-PC7\n",
      "39971.664331571934\n",
      "Finished finding transition rates for PC3-PC7\n",
      "Finished interpolating trajectories for PC3-PC8\n",
      "40216.09065180129\n",
      "Finished finding transition rates for PC3-PC8\n",
      "Finished interpolating trajectories for PC3-PC9\n",
      "40076.14783634426\n",
      "Finished finding transition rates for PC3-PC9\n",
      "Finished interpolating trajectories for PC3-PC10\n",
      "40084.467875443734\n",
      "Finished finding transition rates for PC3-PC10\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for PC4-PC5\n",
      "39515.52005133308\n",
      "Finished finding transition rates for PC4-PC5\n",
      "Finished interpolating trajectories for PC4-PC6\n",
      "39742.714855048755\n",
      "Finished finding transition rates for PC4-PC6\n",
      "Finished interpolating trajectories for PC4-PC7\n",
      "39753.24519051968\n",
      "Finished finding transition rates for PC4-PC7\n",
      "Finished interpolating trajectories for PC4-PC8\n",
      "40070.12836199114\n",
      "Finished finding transition rates for PC4-PC8\n"
     ]
    }
   ],
   "source": [
    "########### ALL PC CGPS's ##############\n",
    "\n",
    "from CustomFunctions.DetailedBalance import get_transition_counts, interpolate_2dtrajectory\n",
    "import itertools\n",
    "\n",
    "specdir = savedir + 'All_CGPS/'\n",
    "if not os.path.exists(specdir):\n",
    "    os.makedirs(specdir)\n",
    "\n",
    "binlist = [i for i in TotalFrame.columns.to_list() if 'bin' in i]\n",
    "for a in binlist:\n",
    "    for b in binlist:\n",
    "        bin1 = a.split('bin')[0]\n",
    "        bin2 = b.split('bin')[0]\n",
    "        if a == b:\n",
    "            continue\n",
    "        \n",
    "        elif (os.path.exists(specdir+f'interpolated_{bin1}-{bin2}_transitions_separated.csv')) & (os.path.exists(specdir+f'interpolated_{bin1}-{bin2}_transition_pairs_separated.csv')):\n",
    "        \n",
    "            transdf_sep = pd.read_csv(specdir+f'interpolated_{bin1}-{bin2}_transitions_separated.csv', index_col=0)\n",
    "            transpairsdf_sep = pd.read_csv(specdir+f'interpolated_{bin1}-{bin2}_transition_pairs_separated.csv', index_col=0)\n",
    "            print(f'Opened {bin1}-{bin2} transition files')\n",
    "            #ensure that DMSO is the first in order\n",
    "            \n",
    "        elif (os.path.exists(specdir+f'interpolated_{bin2}-{bin1}_transitions_separated.csv')) & (os.path.exists(specdir+f'interpolated_{bin2}-{bin1}_transition_pairs_separated.csv')):\n",
    "            print('Already made this plot')\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            if __name__ ==  '__main__':\n",
    "                results = []\n",
    "                pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-1)\n",
    "                for i, cells in TotalFrame.groupby('CellID'):\n",
    "                    cells = cells.sort_values('time').reset_index(drop = True)\n",
    "                    diff = cells.time.diff()\n",
    "                    difflist = [0]\n",
    "                    difflist.extend(diff[diff>5].index.to_list())\n",
    "                    runs = []\n",
    "                    for x in range(len(difflist)-1):\n",
    "                        runs.append(list(range(difflist[x], difflist[x+1])))\n",
    "\n",
    "                    for r in runs:\n",
    "                        r = np.array(r, dtype=int)\n",
    "                        #skip runs less than 3 frames long\n",
    "                        if len(r)<2:\n",
    "                            pass\n",
    "                        else:\n",
    "                            cell = cells.iloc[r]\n",
    "\n",
    "                            pool.apply_async(interpolate_2dtrajectory, args = (\n",
    "                                time_interval,\n",
    "                                cell.CellID.iloc[0],\n",
    "                                cell.frame.to_list(),\n",
    "                                cell[[a,b]].to_numpy(),\n",
    "                                ),\n",
    "                                callback = collect_results)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "\n",
    "\n",
    "            transdf_sep = pd.DataFrame(sum([r[0] for r in results],[]))\n",
    "            transdf_sep = transdf_sep.sort_values(by = ['CellID','frame']).reset_index(drop=True)\n",
    "            transpairsdf_sep = pd.DataFrame(sum([r[1] for r in results],[]))\n",
    "#             transdf_sep['Treatment'] = [m]*len(transdf_sep)\n",
    "#             transpairsdf_sep['Treatment'] = [m]*len(transpairsdf_sep)\n",
    "\n",
    "            transdf_sep.to_csv(specdir+f'interpolated_{bin1}-{bin2}_transitions_separated.csv')\n",
    "            transpairsdf_sep.to_csv(specdir+f'interpolated_{bin1}-{bin2}_transition_pairs_separated.csv')\n",
    "            print(f'Finished interpolating trajectories for {bin1}-{bin2}')\n",
    "            \n",
    "            \n",
    "        ############## get the counts of cells leaving \n",
    "\n",
    "\n",
    "        if os.path.exists(specdir+f'{bin1}-{bin2}_binned_transition_rates_separated.csv'):\n",
    "            trans_rate_df_sep = pd.read_csv(specdir+f'{bin1}-{bin2}_binned_transition_rates_separated.csv', index_col=0)\n",
    "            print(f'Opened {bin1}-{bin2} transition rate files')\n",
    "            \n",
    "        elif os.path.exists(specdir+f'{bin2}-{bin1}_binned_transition_rates_separated.csv'):\n",
    "            print('Already made this plot')\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            trresults = []\n",
    "            if __name__ ==  '__main__':\n",
    "                ttot = transdf_sep.time_elapsed.sum()\n",
    "                print(ttot)\n",
    "                pool = multiprocessing.Pool(processes=60)\n",
    "                results = []\n",
    "                for x in range(nbins):\n",
    "                    for y in range(nbins):\n",
    "                        fromm = transdf_sep[(transdf_sep['from_x'] == x+1) & (transdf_sep['from_y'] == y+1)].reset_index(drop=True).to_dict()\n",
    "                        to = transdf_sep[(transdf_sep['to_x'] == x+1) & (transdf_sep['to_y'] == y+1)].reset_index(drop=True).to_dict()\n",
    "                        pool.apply_async(get_transition_counts, args = (\n",
    "                            x+1,\n",
    "                            y+1,\n",
    "                            fromm,\n",
    "                            to,\n",
    "                            ttot,\n",
    "                            ),\n",
    "                            callback = collect_results)\n",
    "                pool.close()\n",
    "                pool.join()\n",
    "\n",
    "            trans_rate_df_sep = pd.DataFrame(results)\n",
    "#             trans_rate_df_sep['Treatment'] = [m]*len(trans_rate_df_sep)\n",
    "            trans_rate_df_sep = trans_rate_df_sep.sort_values(by = ['x','y']).reset_index(drop=True)\n",
    "\n",
    "            trans_rate_df_sep.to_csv(specdir+f'{bin1}-{bin2}_binned_transition_rates_separated.csv')\n",
    "\n",
    "            print(f'Finished finding transition rates for {bin1}-{bin2}')\n",
    "\n",
    "            \n",
    "            \n",
    "#         ########### PDFs AND PROBABILITY FLUX OF THE SEPARATED MIGRATION MODES #############\n",
    "#         from matplotlib.patches import Ellipse, Rectangle\n",
    "#         from CustomFunctions.DetailedBalance import contour_coords\n",
    "#         # inverse scale for arrows\n",
    "#         scale = 0.0002\n",
    "\n",
    "\n",
    "#         fig, ax = plt.subplots()\n",
    "#         #single colorbar axis\n",
    "#         cbar_ax = fig.add_axes([.98, .2, .015, .5])\n",
    "\n",
    "#         ################ heatmap of probability density #############\n",
    "#         mm = transdf_sep.Treatment.unique()[i]\n",
    "#         mdf = transdf_sep[transdf_sep.Treatment==mm]\n",
    "#         ttot = mdf.time_elapsed.sum()\n",
    "#         #make numpy array with heatmap data\n",
    "#         bighm = np.zeros((nbins,nbins))\n",
    "#         #get total time observed in the system\n",
    "\n",
    "#         for x in range(nbins):\n",
    "#             for y in range(nbins):\n",
    "#                 current =  mdf[(mdf['from_x'] == x+1) & (mdf['from_y'] == y+1)]\n",
    "#                 if current.empty:\n",
    "#                     bighm[y,x] = 0\n",
    "#                 else:\n",
    "#                     bighm[y,x] = current.time_elapsed.sum()/ttot\n",
    "#         #plot heatmap with seaborn\n",
    "#         sns.heatmap(\n",
    "#             bighm,\n",
    "#             vmin=0, vmax=0.05, #center=0,\n",
    "#             cmap='rocket',\n",
    "#             square=True,\n",
    "#             xticklabels = True,\n",
    "#             yticklabels = True,\n",
    "#             ax = ax,\n",
    "#             cbar=i==0,\n",
    "#             cbar_ax = None if i else cbar_ax,\n",
    "#     #         cbar_kws=cbar_kws\n",
    "#         )\n",
    "\n",
    "#         ######################### vector map of probability flux ################\n",
    "#         mm = trans_rate_df_sep.Treatment.unique()[i]\n",
    "#         mdf = trans_rate_df_sep[trans_rate_df_sep.Treatment==mm]\n",
    "\n",
    "#         for x in range(1,nbins+1):\n",
    "#             for y in range(1,nbins+1):\n",
    "#                 current = mdf[(mdf['x'] == x) & (mdf['y'] == y)]\n",
    "#                 xcurrent = (current.x_plus_rate - current.x_minus_rate)/2\n",
    "#                 ycurrent = (current.y_plus_rate - current.y_minus_rate)/2\n",
    "#                 ax.quiver(x-0.5,\n",
    "#                            y-0.5, \n",
    "#                            xcurrent,\n",
    "#                            ycurrent,\n",
    "#                           angles = 'xy',\n",
    "#                           scale_units = 'xy',\n",
    "#                           scale = scale,\n",
    "#     #                       width = 0.012,\n",
    "#     #                       minlength = 0.8,\n",
    "#                           color = 'white')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # axis label stuff\n",
    "#         ax.set_xlabel(bin1, fontsize = 45)\n",
    "#         ax.set_xticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[bin1].to_list()])\n",
    "#         ax.set_xticklabels(ax.get_xticklabels(), fontsize = 22)\n",
    "#         ax.set_yticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[bin2].to_list()])\n",
    "#         ax.set_yticklabels(ax.get_yticklabels(), fontsize = 22)\n",
    "#         ax.set_xlim(0,nbins+1)\n",
    "#         ax.set_ylim(0,nbins+1)\n",
    "#         ax.set_title(mm, fontsize = 45)\n",
    "\n",
    "\n",
    "#         # adjust colorbar tick label size\n",
    "#         cbar_ax.set_yticklabels(cbar_ax.get_yticklabels(),fontsize=18)\n",
    "#         #set axis title\n",
    "#         graphaxes[0].set_ylabel(bin2, fontsize = 45)\n",
    "\n",
    "\n",
    "\n",
    "#         ########## add scale for the vectors ##########\n",
    "#         #legend background\n",
    "#         lxp = 0.125\n",
    "#         lyp = 0.125\n",
    "#         rect = Rectangle((lxp, lyp), 1.8, 1.8, linewidth=1, edgecolor='black', facecolor='#80858a')\n",
    "#         ax.add_patch(rect)\n",
    "#         rect.set_zorder(4 * 5)\n",
    "#         #x-axis legend arrow\n",
    "#         ax.quiver(lxp+0.5,lyp+0.5,1*scale,0,angles = 'xy',scale_units = 'xy',scale = scale,color = \"white\",zorder = 4 * 5)\n",
    "#         #x-axis legend text\n",
    "#         xsc = f'{(np.diff(centers[bin1]).mean()/time_interval)*scale:.1e}'\n",
    "#         xsc = xsc.split('-')[0] + str(int(xsc.split('e')[1]))\n",
    "#         ax.text(lxp+0.25,lyp+0.05,xsc+' $s^{-1}$', color = 'white', fontsize = 13, fontweight = 'bold',zorder = 4 * 5)\n",
    "#         #y-axis legend arrow\n",
    "#         ax.quiver(lxp+0.5,lyp+0.5,0,1*scale,angles = 'xy',scale_units = 'xy',scale = scale,color = 'white',zorder = 4 * 5)\n",
    "#         #y-axis legend text\n",
    "#         ysc = f'{(np.diff(centers[bin2]).mean()/time_interval)*scale:.1e}'\n",
    "#         ysc = ysc.split('-')[0] + str(int(ysc.split('e')[1]))\n",
    "#         ax.text(lxp+0.05,lyp+0.3,ysc+' $s^{-1}$', rotation = 'vertical', color = 'white', fontsize = 13, fontweight = 'bold',zorder = 4 * 5)\n",
    "\n",
    "\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(specdir + f'{bin1}-{bin2} probability flux and pdf separated.png', bbox_inches='tight')\n",
    "#         plt.close()\n",
    "#         print(f'Saved {bin1}-{bin2} plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### ONE BIG DIAGONAL GRAPH OF ALL PC CGPS's ##############\n",
    "\n",
    "from CustomFunctions.DetailedBalance import get_transition_counts, interpolate_2dtrajectory\n",
    "import itertools\n",
    "from matplotlib.patches import Ellipse, Rectangle\n",
    "from CustomFunctions.DetailedBalance import contour_coords\n",
    "\n",
    "binlist = [i for i in TotalFrame.columns.to_list() if 'bin' in i]\n",
    "fig, axes = plt.subplots(len(binlist),len(binlist), figsize = (30,30))\n",
    "nn = 0\n",
    "for a in binlist[::-1]:\n",
    "    for b in binlist[::-1]:\n",
    "        bin1 = a.split('bin')[0]\n",
    "        bin2 = b.split('bin')[0]\n",
    "        \n",
    "        ax = axes.flatten()[::-1][nn]\n",
    "        ############## get the counts of cells leaving \n",
    "\n",
    "\n",
    "        if os.path.exists(savedir+ 'All_CGPS/' +f'{bin1}-{bin2}_binned_transition_rates_separated.csv'):\n",
    "            transdf_sep = pd.read_csv(savedir+ 'All_CGPS/' +f'interpolated_{bin1}-{bin2}_transitions_separated.csv', index_col=0)\n",
    "            trans_rate_df_sep = pd.read_csv(savedir+ 'All_CGPS/' +f'{bin1}-{bin2}_binned_transition_rates_separated.csv', index_col=0)\n",
    "            print(f'Opened {bin1}-{bin2} transition rate files')\n",
    "            \n",
    "            ########### PDFs AND PROBABILITY FLUX OF THE SEPARATED MIGRATION MODES #############\n",
    "            # inverse scale for arrows\n",
    "            scale = 0.0005\n",
    "\n",
    "            \n",
    "#             #single colorbar axis\n",
    "#             cbar_ax = fig.add_axes([.98, .2, .015, .5])\n",
    "\n",
    "            ################ heatmap of probability density #############\n",
    "            ttot = transdf_sep.time_elapsed.sum()\n",
    "            #make numpy array with heatmap data\n",
    "            bighm = np.zeros((nbins,nbins))\n",
    "            #get total time observed in the system\n",
    "\n",
    "            for x in range(nbins):\n",
    "                for y in range(nbins):\n",
    "                    current =  transdf_sep[(transdf_sep['from_x'] == x+1) & (transdf_sep['from_y'] == y+1)]\n",
    "                    if current.empty:\n",
    "                        bighm[y,x] = 0\n",
    "                    else:\n",
    "                        bighm[y,x] = current.time_elapsed.sum()/ttot\n",
    "            #plot heatmap with seaborn\n",
    "            sns.heatmap(\n",
    "                bighm,\n",
    "                vmin=0, vmax=0.045, #center=0,\n",
    "                cmap='rocket',\n",
    "                square=True,\n",
    "                xticklabels = True,\n",
    "                yticklabels = True,\n",
    "                ax = ax,\n",
    "#                 cbar=i==0,\n",
    "#                 cbar_ax = None if i else cbar_ax,\n",
    "        #         cbar_kws=cbar_kws\n",
    "            )\n",
    "\n",
    "            ######################### vector map of probability flux ################\n",
    "            for x in range(1,nbins+1):\n",
    "                for y in range(1,nbins+1):\n",
    "                    current = trans_rate_df_sep[(trans_rate_df_sep['x'] == x) & (trans_rate_df_sep['y'] == y)]\n",
    "                    xcurrent = (current.x_plus_rate - current.x_minus_rate)/2\n",
    "                    ycurrent = (current.y_plus_rate - current.y_minus_rate)/2\n",
    "                    ax.quiver(x-0.5,\n",
    "                               y-0.5, \n",
    "                               xcurrent,\n",
    "                               ycurrent,\n",
    "                              angles = 'xy',\n",
    "                              scale_units = 'xy',\n",
    "                              scale = scale,\n",
    "        #                       width = 0.012,\n",
    "        #                       minlength = 0.8,\n",
    "                              color = 'white')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # axis label stuff\n",
    "\n",
    "            ax.set_xticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[bin1].to_list()])\n",
    "            ax.set_xticklabels(ax.get_xticklabels())#, fontsize = 22)\n",
    "            ax.set_yticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[bin2].to_list()])\n",
    "            ax.set_yticklabels(ax.get_yticklabels())#, fontsize = 22)\n",
    "            ax.set_xlim(0,nbins+1)\n",
    "            ax.set_ylim(0,nbins+1)\n",
    "            \n",
    "\n",
    "\n",
    "            if a == binlist[0]:\n",
    "                ax.set_title(bin2)#, fontsize = 45)\n",
    "            if b == binlist[1]:\n",
    "                ax.set_ylabel(bin1)#, fontsize = 45)\n",
    "            \n",
    "            nn=nn+1\n",
    "        else:\n",
    "            print('remove this plot')\n",
    "            ax.remove()\n",
    "            nn=nn+1\n",
    "            \n",
    "            \n",
    "            \n",
    "plt.tight_layout() \n",
    "plt.savefig(specdir + f'all cgps flux and pdf diagonal.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "255929a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PC1', 'PC2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin1, bin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903764bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished interpolating trajectories for Cell_Volume-Cell_SurfaceArea\n",
      "69423.71235948785\n",
      "9578.435879733293\n",
      "64372.28280905215\n",
      "Finished finding transition rates for Cell_Volume-Cell_SurfaceArea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aaron\\anaconda3\\envs\\abhishape\\lib\\site-packages\\ipykernel_launcher.py:215: MatplotlibDeprecationWarning: Passing the minor parameter of set_xticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
      "C:\\Users\\Aaron\\anaconda3\\envs\\abhishape\\lib\\site-packages\\ipykernel_launcher.py:217: MatplotlibDeprecationWarning: Passing the minor parameter of set_yticks() positionally is deprecated since Matplotlib 3.2; the parameter will become keyword-only two minor releases later.\n",
      "C:\\Users\\Aaron\\anaconda3\\envs\\abhishape\\lib\\site-packages\\ipykernel_launcher.py:253: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Cell_Volume_bins-Cell_SurfaceArea_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Cell_Elongation\n",
      "70667.84575426238\n",
      "9883.437181028145\n",
      "65805.07569279756\n",
      "Finished finding transition rates for Cell_Volume-Cell_Elongation\n",
      "Saved Cell_Volume_bins-Cell_Elongation_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Cell_UpDownAngle\n",
      "71255.57616833663\n",
      "9972.064206235085\n",
      "66432.5375229298\n",
      "Finished finding transition rates for Cell_Volume-Cell_UpDownAngle\n",
      "Saved Cell_Volume_bins-Cell_UpDownAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Cell_LeftRightAngle\n",
      "69734.17696050346\n",
      "9614.902498910506\n",
      "64855.94927991344\n",
      "Finished finding transition rates for Cell_Volume-Cell_LeftRightAngle\n",
      "Saved Cell_Volume_bins-Cell_LeftRightAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Volume_Front_Ratio\n",
      "70816.76120062535\n",
      "10040.244757025648\n",
      "66127.24451263946\n",
      "Finished finding transition rates for Cell_Volume-Volume_Front_Ratio\n",
      "Saved Cell_Volume_bins-Volume_Front_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Volume_Right_Ratio\n",
      "71225.73060493814\n",
      "9985.063305160542\n",
      "66324.59813775221\n",
      "Finished finding transition rates for Cell_Volume-Volume_Right_Ratio\n",
      "Saved Cell_Volume_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_Volume-Volume_Top_Ratio\n",
      "71662.3726593625\n",
      "10115.84884601993\n",
      "66770.86640857947\n",
      "Finished finding transition rates for Cell_Volume-Volume_Top_Ratio\n",
      "Saved Cell_Volume_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Cell_Elongation\n",
      "71269.33592517464\n",
      "10134.011212971896\n",
      "66266.20470709958\n",
      "Finished finding transition rates for Cell_SurfaceArea-Cell_Elongation\n",
      "Saved Cell_SurfaceArea_bins-Cell_Elongation_bins plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Cell_UpDownAngle\n",
      "71581.25696041464\n",
      "10091.342701945996\n",
      "66661.49859679412\n",
      "Finished finding transition rates for Cell_SurfaceArea-Cell_UpDownAngle\n",
      "Saved Cell_SurfaceArea_bins-Cell_UpDownAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Cell_LeftRightAngle\n",
      "70628.80030226674\n",
      "9887.233909812028\n",
      "65726.30079403127\n",
      "Finished finding transition rates for Cell_SurfaceArea-Cell_LeftRightAngle\n",
      "Saved Cell_SurfaceArea_bins-Cell_LeftRightAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Volume_Front_Ratio\n",
      "71507.70984124552\n",
      "10033.340606631555\n",
      "66353.29945855451\n",
      "Finished finding transition rates for Cell_SurfaceArea-Volume_Front_Ratio\n",
      "Saved Cell_SurfaceArea_bins-Volume_Front_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Volume_Right_Ratio\n",
      "71659.76090060169\n",
      "10136.701924689238\n",
      "66625.56466899245\n",
      "Finished finding transition rates for Cell_SurfaceArea-Volume_Right_Ratio\n",
      "Saved Cell_SurfaceArea_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_SurfaceArea-Volume_Top_Ratio\n",
      "71974.30528114198\n",
      "10189.264402266279\n",
      "66858.97388900736\n",
      "Finished finding transition rates for Cell_SurfaceArea-Volume_Top_Ratio\n",
      "Saved Cell_SurfaceArea_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Cell_Elongation-Cell_UpDownAngle\n",
      "71955.16013524475\n",
      "10191.518541621172\n",
      "66971.23708838043\n",
      "Finished finding transition rates for Cell_Elongation-Cell_UpDownAngle\n",
      "Saved Cell_Elongation_bins-Cell_UpDownAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_Elongation-Cell_LeftRightAngle\n",
      "71188.87386605739\n",
      "9915.7171612691\n",
      "66230.20546643087\n",
      "Finished finding transition rates for Cell_Elongation-Cell_LeftRightAngle\n",
      "Saved Cell_Elongation_bins-Cell_LeftRightAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_Elongation-Volume_Front_Ratio\n",
      "71845.91267807197\n",
      "10189.991584162915\n",
      "66825.87446972067\n",
      "Finished finding transition rates for Cell_Elongation-Volume_Front_Ratio\n",
      "Saved Cell_Elongation_bins-Volume_Front_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_Elongation-Volume_Right_Ratio\n",
      "72003.68241785196\n",
      "10264.434128751203\n",
      "66935.6715147451\n",
      "Finished finding transition rates for Cell_Elongation-Volume_Right_Ratio\n",
      "Saved Cell_Elongation_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_Elongation-Volume_Top_Ratio\n",
      "72366.14463612252\n",
      "10270.258086205036\n",
      "67430.39239484801\n",
      "Finished finding transition rates for Cell_Elongation-Volume_Top_Ratio\n",
      "Saved Cell_Elongation_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Cell_UpDownAngle-Cell_LeftRightAngle\n",
      "71147.98236348122\n",
      "9891.575800459435\n",
      "66405.02926837807\n",
      "Finished finding transition rates for Cell_UpDownAngle-Cell_LeftRightAngle\n",
      "Saved Cell_UpDownAngle_bins-Cell_LeftRightAngle_bins plot\n",
      "Finished interpolating trajectories for Cell_UpDownAngle-Volume_Front_Ratio\n",
      "72044.91049572869\n",
      "10158.464373496556\n",
      "67016.48600718653\n",
      "Finished finding transition rates for Cell_UpDownAngle-Volume_Front_Ratio\n",
      "Saved Cell_UpDownAngle_bins-Volume_Front_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_UpDownAngle-Volume_Right_Ratio\n",
      "72301.84344939946\n",
      "10195.927624011525\n",
      "67229.14704706792\n",
      "Finished finding transition rates for Cell_UpDownAngle-Volume_Right_Ratio\n",
      "Saved Cell_UpDownAngle_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_UpDownAngle-Volume_Top_Ratio\n",
      "72410.92288226397\n",
      "10240.232829499135\n",
      "67360.0999990893\n",
      "Finished finding transition rates for Cell_UpDownAngle-Volume_Top_Ratio\n",
      "Saved Cell_UpDownAngle_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Cell_LeftRightAngle-Volume_Front_Ratio\n",
      "71242.71238611198\n",
      "10041.778409447481\n",
      "66353.99566058133\n",
      "Finished finding transition rates for Cell_LeftRightAngle-Volume_Front_Ratio\n",
      "Saved Cell_LeftRightAngle_bins-Volume_Front_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_LeftRightAngle-Volume_Right_Ratio\n",
      "71535.93743167512\n",
      "10133.267176405601\n",
      "66567.26417029895\n",
      "Finished finding transition rates for Cell_LeftRightAngle-Volume_Right_Ratio\n",
      "Saved Cell_LeftRightAngle_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Cell_LeftRightAngle-Volume_Top_Ratio\n",
      "71932.1665157415\n",
      "10178.847040689456\n",
      "66978.0492946508\n",
      "Finished finding transition rates for Cell_LeftRightAngle-Volume_Top_Ratio\n",
      "Saved Cell_LeftRightAngle_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Volume_Front_Ratio-Volume_Right_Ratio\n",
      "72085.89035865078\n",
      "10216.23138416361\n",
      "67156.61791164748\n",
      "Finished finding transition rates for Volume_Front_Ratio-Volume_Right_Ratio\n",
      "Saved Volume_Front_Ratio_bins-Volume_Right_Ratio_bins plot\n",
      "Finished interpolating trajectories for Volume_Front_Ratio-Volume_Top_Ratio\n",
      "72412.66838125794\n",
      "10262.509605417472\n",
      "67335.86252169497\n",
      "Finished finding transition rates for Volume_Front_Ratio-Volume_Top_Ratio\n",
      "Saved Volume_Front_Ratio_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Finished interpolating trajectories for Volume_Right_Ratio-Volume_Top_Ratio\n",
      "72478.88773646997\n",
      "10327.455686019719\n",
      "67393.82771135207\n",
      "Finished finding transition rates for Volume_Right_Ratio-Volume_Top_Ratio\n",
      "Saved Volume_Right_Ratio_bins-Volume_Top_Ratio_bins plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n",
      "Already made this plot\n"
     ]
    }
   ],
   "source": [
    "########### ALL METRIC CGPS's ###################\n",
    "\n",
    "from CustomFunctions.DetailedBalance import get_transition_counts, interpolate_2dtrajectory\n",
    "from CustomFunctions import shapePCAtools\n",
    "import itertools\n",
    "\n",
    "\n",
    "metriclist = ['Cell_Volume','Cell_SurfaceArea', 'Cell_Elongation', 'Cell_UpDownAngle', 'Cell_LeftRightAngle',\n",
    "           'Volume_Front_Ratio', 'Volume_Right_Ratio', 'Volume_Top_Ratio']\n",
    "for a in metriclist:\n",
    "    for b in metriclist:\n",
    "        bin1 = a + '_bins'\n",
    "        bin2 = b + '_bins'\n",
    "        \n",
    "        centers = []\n",
    "        for q in [a, b]:\n",
    "            df_digit, bin_indexes, (bin_centers, pc_std) = shapePCAtools.digitize_shape_mode(\n",
    "                df = TotalFrame,\n",
    "                feature = q,\n",
    "                nbins = nbins,\n",
    "                filter_based_on = metriclist,\n",
    "                filter_extremes_pct = 0,\n",
    "                save = None,\n",
    "                return_freqs_per_structs = False,\n",
    "            )\n",
    "            #put bin_indexes into a larger list that I can later iterate through\n",
    "            TotalFrame[q+'_bins'] = df_digit.bin\n",
    "            #get bin centers for each PC\n",
    "            centers.append(pd.Series(bin_centers*pc_std, name=q))\n",
    "        centers = pd.DataFrame(centers).T\n",
    "\n",
    "        if a == b:\n",
    "            continue\n",
    "        \n",
    "        elif (os.path.exists(savedir+f'interpolated_{a}-{b}_transitions_separated.csv')) & (os.path.exists(savedir+f'interpolated_{a}-{b}_transition_pairs_separated.csv')):\n",
    "        \n",
    "            transdf_sep = pd.read_csv(savedir+f'interpolated_{a}-{b}_transitions_separated.csv', index_col=0)\n",
    "            transpairsdf_sep = pd.read_csv(savedir+f'interpolated_{a}-{b}_transition_pairs_separated.csv', index_col=0)\n",
    "            print(f'Opened {a}-{b} transition files')\n",
    "            #ensure that DMSO is the first in order\n",
    "            transdf_sep['Treatment'] = pd.Categorical(transdf_sep.Treatment, categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "            transdf_sep = transdf_sep.sort_values(by='Treatment')\n",
    "            transpairsdf_sep['Treatment'] = pd.Categorical(transpairsdf_sep.Treatment, categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "            transpairsdf_sep = transpairsdf_sep.sort_values(by='Treatment')\n",
    "            \n",
    "        elif (os.path.exists(savedir+f'interpolated_{b}-{a}_transitions_separated.csv')) & (os.path.exists(savedir+f'interpolated_{b}-{a}_transition_pairs_separated.csv')):\n",
    "            print('Already made this plot')\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            if __name__ ==  '__main__':\n",
    "                migresults = []\n",
    "                for m, Mig in TotalFrame.groupby('Treatment'):\n",
    "                    results = []\n",
    "                    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count()-1)\n",
    "                    for i, cells in Mig.groupby('CellID'):\n",
    "                        cells = cells.sort_values('frame').reset_index(drop = True)\n",
    "                        runs = list()\n",
    "                        #######https://stackoverflow.com/questions/2361945/detecting-consecutive-integers-in-a-list\n",
    "                        for k, g in groupby(enumerate(cells['frame']), lambda ix: ix[0] - ix[1]):\n",
    "                            currentrun = list(map(itemgetter(1), g))\n",
    "                            list.append(runs, currentrun)\n",
    "\n",
    "                        for r in runs:\n",
    "                            r = np.array(r, dtype=int)\n",
    "                            #skip runs less than 3 frames long\n",
    "                            if len(r)<2:\n",
    "                                pass\n",
    "                            else:\n",
    "                                cell = cells.iloc[[cells[cells.frame==y].index[0] for y in r]]\n",
    "\n",
    "                                pool.apply_async(interpolate_2dtrajectory, args = (\n",
    "                                    time_interval,\n",
    "                                    cell.CellID.iloc[0],\n",
    "                                    cell.frame.to_list(),\n",
    "                                    cell[[bin1,bin2]].to_numpy(),\n",
    "                                    ),\n",
    "                                    callback = collect_results)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "\n",
    "                    transdf_sep = pd.DataFrame(sum([r[0] for r in results],[]))\n",
    "                    transdf_sep = transdf_sep.sort_values(by = ['CellID','frame']).reset_index(drop=True)\n",
    "                    transpairsdf_sep = pd.DataFrame(sum([r[1] for r in results],[]))\n",
    "                    transdf_sep['Treatment'] = pd.Categorical([m]*len(transdf_sep), categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "                    transpairsdf_sep['Treatment'] = pd.Categorical([m]*len(transpairsdf_sep), categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "                    migresults.append([transdf_sep,transpairsdf_sep])\n",
    "\n",
    "            transdf_sep = pd.concat([mi[0] for mi in migresults])\n",
    "            transpairsdf_sep = pd.concat([mi[1] for mi in migresults])\n",
    "            transdf_sep.to_csv(savedir+f'interpolated_{a}-{b}_transitions_separated.csv')\n",
    "            transpairsdf_sep.to_csv(savedir+f'interpolated_{a}-{b}_transition_pairs_separated.csv')\n",
    "            del migresults\n",
    "            print(f'Finished interpolating trajectories for {a}-{b}')\n",
    "            \n",
    "            \n",
    "        ############## get the counts of cells leaving \n",
    "\n",
    "\n",
    "        if os.path.exists(savedir+f'{a}-{b}_binned_transition_rates_separated.csv'):\n",
    "            trans_rate_df_sep = pd.read_csv(savedir+f'{a}-{b}_binned_transition_rates_separated.csv', index_col=0)\n",
    "            print(f'Opened {a}-{b} transition rate files')\n",
    "            #ensure that DMSO is the first in order\n",
    "            trans_rate_df_sep['Treatment'] = pd.Categorical(trans_rate_df_sep.Treatment, categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "            trans_rate_df_sep = trans_rate_df_sep.sort_values(by='Treatment')\n",
    "            \n",
    "        elif os.path.exists(savedir+f'{b}-{a}_binned_transition_rates_separated.csv'):\n",
    "            print('Already made this plot')\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            trresults = []\n",
    "            if __name__ ==  '__main__':\n",
    "                for m, mig in transdf_sep.groupby('Treatment'):\n",
    "                    ttot = mig.time_elapsed.sum()\n",
    "                    print(ttot)\n",
    "                    pool = multiprocessing.Pool(processes=60)\n",
    "                    results = []\n",
    "                    for x in range(nbins):\n",
    "                        for y in range(nbins):\n",
    "                            fromm = mig[(mig['from_x'] == x+1) & (mig['from_y'] == y+1)].reset_index(drop=True).to_dict()\n",
    "                            to = mig[(mig['to_x'] == x+1) & (mig['to_y'] == y+1)].reset_index(drop=True).to_dict()\n",
    "                            pool.apply_async(get_transition_counts, args = (\n",
    "                                x+1,\n",
    "                                y+1,\n",
    "                                fromm,\n",
    "                                to,\n",
    "                                ttot,\n",
    "                                ),\n",
    "                                callback = collect_results)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "\n",
    "                    trans_rate_df_sep = pd.DataFrame(results)\n",
    "                    trans_rate_df_sep['Treatment'] = pd.Categorical([m]*len(trans_rate_df_sep), categories=['Random','Pre-Galvanotaxis','Galvanotaxis'], ordered=True)\n",
    "                    trans_rate_df_sep = trans_rate_df_sep.sort_values(by = ['x','y']).reset_index(drop=True)\n",
    "                    trresults.append(trans_rate_df_sep)\n",
    "\n",
    "            trans_rate_df_sep = pd.concat(trresults)\n",
    "            trans_rate_df_sep.to_csv(savedir+f'{a}-{b}_binned_transition_rates_separated.csv')\n",
    "            del trresults\n",
    "\n",
    "            print(f'Finished finding transition rates for {a}-{b}')\n",
    "\n",
    "            \n",
    "            \n",
    "        ########### PDFs AND PROBABILITY FLUX OF THE SEPARATED MIGRATION MODES #############\n",
    "        from matplotlib.patches import Ellipse, Rectangle\n",
    "        from CustomFunctions.DetailedBalance import contour_coords\n",
    "        # inverse scale for arrows\n",
    "        scale = 0.0002\n",
    "\n",
    "\n",
    "        fig, graphaxes = plt.subplots(1,3,figsize=(7.5+(10*(len(trans_rate_df_sep.Treatment.unique())-1)),10))\n",
    "        #single colorbar axis\n",
    "        cbar_ax = fig.add_axes([.98, .2, .015, .5])\n",
    "\n",
    "        for i, ax in enumerate(graphaxes):\n",
    "            ################ heatmap of probability density #############\n",
    "            mm = transdf_sep.Treatment.unique()[i]\n",
    "            mdf = transdf_sep[transdf_sep.Treatment==mm]\n",
    "            ttot = mdf.time_elapsed.sum()\n",
    "            #make numpy array with heatmap data\n",
    "            bighm = np.zeros((nbins,nbins))\n",
    "            #get total time observed in the system\n",
    "\n",
    "            for x in range(nbins):\n",
    "                for y in range(nbins):\n",
    "                    current =  mdf[(mdf['from_x'] == x+1) & (mdf['from_y'] == y+1)]\n",
    "                    if current.empty:\n",
    "                        bighm[y,x] = 0\n",
    "                    else:\n",
    "                        bighm[y,x] = current.time_elapsed.sum()/ttot\n",
    "            #plot heatmap with seaborn\n",
    "            sns.heatmap(\n",
    "                bighm,\n",
    "                vmin=0, vmax=0.05, #center=0,\n",
    "                cmap='rocket',\n",
    "                square=True,\n",
    "                xticklabels = True,\n",
    "                yticklabels = True,\n",
    "                ax = ax,\n",
    "                cbar=i==0,\n",
    "                cbar_ax = None if i else cbar_ax,\n",
    "        #         cbar_kws=cbar_kws\n",
    "            )\n",
    "\n",
    "            ######################### vector map of probability flux ################\n",
    "            mm = trans_rate_df_sep.Treatment.unique()[i]\n",
    "            mdf = trans_rate_df_sep[trans_rate_df_sep.Treatment==mm]\n",
    "\n",
    "            for x in range(1,nbins+1):\n",
    "                for y in range(1,nbins+1):\n",
    "                    current = mdf[(mdf['x'] == x) & (mdf['y'] == y)]\n",
    "                    xcurrent = (current.x_plus_rate - current.x_minus_rate)/2\n",
    "                    ycurrent = (current.y_plus_rate - current.y_minus_rate)/2\n",
    "                    ax.quiver(x-0.5,\n",
    "                               y-0.5, \n",
    "                               xcurrent,\n",
    "                               ycurrent,\n",
    "                              angles = 'xy',\n",
    "                              scale_units = 'xy',\n",
    "                              scale = scale,\n",
    "        #                       width = 0.012,\n",
    "        #                       minlength = 0.8,\n",
    "                              color = 'white')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # axis label stuff\n",
    "            ax.set_xlabel(a, fontsize = 45)\n",
    "            ax.set_xticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[a].to_list()])\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), fontsize = 22)\n",
    "            ax.set_yticks(np.arange(0.5,nbins+0.5),[round(x,1) for x in centers[b].to_list()])\n",
    "            ax.set_yticklabels(ax.get_yticklabels(), fontsize = 22)\n",
    "            ax.set_xlim(0,nbins+1)\n",
    "            ax.set_ylim(0,nbins+1)\n",
    "            ax.set_title(mm, fontsize = 45)\n",
    "\n",
    "\n",
    "        # adjust colorbar tick label size\n",
    "        cbar_ax.set_yticklabels(cbar_ax.get_yticklabels(),fontsize=18)\n",
    "        #set axis title\n",
    "        graphaxes[0].set_ylabel(b, fontsize = 45)\n",
    "\n",
    "\n",
    "\n",
    "        ########## add scale for the vectors ##########\n",
    "        #legend background\n",
    "        lxp = 0.125\n",
    "        lyp = 0.125\n",
    "        rect = Rectangle((lxp, lyp), 1.8, 1.8, linewidth=1, edgecolor='black', facecolor='#80858a')\n",
    "        graphaxes[0].add_patch(rect)\n",
    "        rect.set_zorder(4 * 5)\n",
    "        #x-axis legend arrow\n",
    "        graphaxes[0].quiver(lxp+0.5,lyp+0.5,1*scale,0,angles = 'xy',scale_units = 'xy',scale = scale,color = \"white\",zorder = 4 * 5)\n",
    "        #x-axis legend text\n",
    "        xsc = f'{(np.diff(centers[a]).mean()/time_interval)*scale:.1e}'\n",
    "        xsc = xsc.split('-')[0] + str(int(xsc.split('e')[1]))\n",
    "        graphaxes[0].text(lxp+0.25,lyp+0.05,xsc+' $s^{-1}$', color = 'white', fontsize = 13, fontweight = 'bold',zorder = 4 * 5)\n",
    "        #y-axis legend arrow\n",
    "        graphaxes[0].quiver(lxp+0.5,lyp+0.5,0,1*scale,angles = 'xy',scale_units = 'xy',scale = scale,color = 'white',zorder = 4 * 5)\n",
    "        #y-axis legend text\n",
    "        ysc = f'{(np.diff(centers[b]).mean()/time_interval)*scale:.1e}'\n",
    "        ysc = ysc.split('-')[0] + str(int(ysc.split('e')[1]))\n",
    "        graphaxes[0].text(lxp+0.05,lyp+0.3,ysc+' $s^{-1}$', rotation = 'vertical', color = 'white', fontsize = 13, fontweight = 'bold',zorder = 4 * 5)\n",
    "\n",
    "\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savedir + f'{bin1}-{bin2} probability flux and pdf separated.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f'Saved {bin1}-{bin2} plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740cb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
